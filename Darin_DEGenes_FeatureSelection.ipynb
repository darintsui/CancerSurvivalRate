{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d119b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import statsmodels.api as sm\n",
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b230cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = pd.read_csv('../P4/Gene_expression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cffe711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-05-4244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-05-4249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-05-4382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-05-4384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-05-4389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>TCGA-NJ-A55O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>TCGA-NJ-A55R</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>TCGA-NJ-A7XG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>TCGA-O1-A52J</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>TCGA-S2-AA1A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       patient_id  label\n",
       "0    TCGA-05-4244      0\n",
       "1    TCGA-05-4249      1\n",
       "2    TCGA-05-4382      0\n",
       "3    TCGA-05-4384      0\n",
       "4    TCGA-05-4389      1\n",
       "..            ...    ...\n",
       "402  TCGA-NJ-A55O      0\n",
       "403  TCGA-NJ-A55R      0\n",
       "404  TCGA-NJ-A7XG      0\n",
       "405  TCGA-O1-A52J      1\n",
       "406  TCGA-S2-AA1A      0\n",
       "\n",
       "[407 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv('labels.csv')\n",
    "# y = y.drop('Unnamed: 0',axis =1 )\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f043997",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = y['patient_id']\n",
    "meta_file = y.merge(expression)\n",
    "meta_file = meta_file.drop(['patient_id','sample_type'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "389198c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_file.columns = meta_file.columns.str.replace(r'\\|.*', '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75f36547",
   "metadata": {},
   "source": [
    "## Import DE Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "855f7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = pd.read_csv('data/top_30_DEgenes.txt', delimiter='\\t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ff9ccca",
   "metadata": {},
   "source": [
    "### Add metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfcc8bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add patient_id back\n",
    "meta_file['patient_id'] = patient_id\n",
    "\n",
    "# Add metadata to meta_file\n",
    "metadata_final = pd.read_csv('metadata_final_no_os.csv')\n",
    "# changing the gender to binary male=0, female=1\n",
    "metadata_final['gender'] = metadata_final['gender'].replace({'MALE': 0, 'FEMALE': 1})\n",
    "# changing the tumor stage to binary\n",
    "metadata_final['tumor_stage'] = metadata_final['tumor_stage'].replace({'Early': 0, 'Late': 1})\n",
    "# changing the smoker status to binary\n",
    "metadata_final['is_smoker'] = metadata_final['is_smoker'].replace({bool(False): 0, bool(True): 1})\n",
    "meta_file = meta_file.merge(metadata_final, how='left', on='patient_id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e24d5f2d",
   "metadata": {},
   "source": [
    "### Permutations of Metadata for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "375ef237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>?|100133144</th>\n",
       "      <th>?|100134869</th>\n",
       "      <th>?|10357</th>\n",
       "      <th>?|10431</th>\n",
       "      <th>?|155060</th>\n",
       "      <th>?|26823</th>\n",
       "      <th>?|340602</th>\n",
       "      <th>?|388795</th>\n",
       "      <th>?|390284</th>\n",
       "      <th>...</th>\n",
       "      <th>ZZZ3|26009</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age_at_initial_pathologic_diagnosis_x</th>\n",
       "      <th>gender_x</th>\n",
       "      <th>tumor_stage_x</th>\n",
       "      <th>is_smoker_x</th>\n",
       "      <th>age_at_initial_pathologic_diagnosis_y</th>\n",
       "      <th>gender_y</th>\n",
       "      <th>tumor_stage_y</th>\n",
       "      <th>is_smoker_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.115255</td>\n",
       "      <td>0.097686</td>\n",
       "      <td>-1.940808</td>\n",
       "      <td>-0.033268</td>\n",
       "      <td>1.057022</td>\n",
       "      <td>1.176377</td>\n",
       "      <td>-0.577514</td>\n",
       "      <td>1.530721</td>\n",
       "      <td>0.136966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447237</td>\n",
       "      <td>TCGA-05-4244</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.233267</td>\n",
       "      <td>0.219007</td>\n",
       "      <td>-0.289184</td>\n",
       "      <td>0.202607</td>\n",
       "      <td>-0.069052</td>\n",
       "      <td>1.877450</td>\n",
       "      <td>-0.577514</td>\n",
       "      <td>0.029955</td>\n",
       "      <td>0.027188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096801</td>\n",
       "      <td>TCGA-05-4249</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.248854</td>\n",
       "      <td>-0.384813</td>\n",
       "      <td>-0.533564</td>\n",
       "      <td>-0.173685</td>\n",
       "      <td>0.583903</td>\n",
       "      <td>0.236868</td>\n",
       "      <td>1.884460</td>\n",
       "      <td>0.123771</td>\n",
       "      <td>-0.210492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019820</td>\n",
       "      <td>TCGA-05-4382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.015130</td>\n",
       "      <td>-1.252003</td>\n",
       "      <td>-0.898805</td>\n",
       "      <td>-1.181021</td>\n",
       "      <td>0.757503</td>\n",
       "      <td>0.484314</td>\n",
       "      <td>-0.577514</td>\n",
       "      <td>-0.013923</td>\n",
       "      <td>0.260217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236221</td>\n",
       "      <td>TCGA-05-4384</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.816478</td>\n",
       "      <td>0.346711</td>\n",
       "      <td>-1.143054</td>\n",
       "      <td>1.242887</td>\n",
       "      <td>-1.570895</td>\n",
       "      <td>-0.056828</td>\n",
       "      <td>-0.577514</td>\n",
       "      <td>-0.166251</td>\n",
       "      <td>-0.193914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356558</td>\n",
       "      <td>TCGA-05-4389</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0</td>\n",
       "      <td>0.593944</td>\n",
       "      <td>0.996343</td>\n",
       "      <td>-0.009038</td>\n",
       "      <td>0.047639</td>\n",
       "      <td>0.668383</td>\n",
       "      <td>1.340455</td>\n",
       "      <td>-0.577514</td>\n",
       "      <td>-1.208640</td>\n",
       "      <td>-0.104800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396243</td>\n",
       "      <td>TCGA-NJ-A55A</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.069018</td>\n",
       "      <td>-0.011506</td>\n",
       "      <td>-0.817153</td>\n",
       "      <td>-0.316691</td>\n",
       "      <td>1.148248</td>\n",
       "      <td>0.675043</td>\n",
       "      <td>0.645656</td>\n",
       "      <td>2.908490</td>\n",
       "      <td>-1.628148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263652</td>\n",
       "      <td>TCGA-NJ-A55O</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0</td>\n",
       "      <td>1.749735</td>\n",
       "      <td>2.648401</td>\n",
       "      <td>-0.450322</td>\n",
       "      <td>-0.660086</td>\n",
       "      <td>1.016852</td>\n",
       "      <td>-0.892399</td>\n",
       "      <td>-0.577514</td>\n",
       "      <td>0.941106</td>\n",
       "      <td>-1.506687</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.338024</td>\n",
       "      <td>TCGA-NJ-A55R</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1</td>\n",
       "      <td>0.486836</td>\n",
       "      <td>1.062102</td>\n",
       "      <td>-1.368185</td>\n",
       "      <td>0.780825</td>\n",
       "      <td>0.141787</td>\n",
       "      <td>3.015645</td>\n",
       "      <td>1.099217</td>\n",
       "      <td>0.123525</td>\n",
       "      <td>-0.071799</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000029</td>\n",
       "      <td>TCGA-NJ-A7XG</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0</td>\n",
       "      <td>0.906803</td>\n",
       "      <td>-0.184996</td>\n",
       "      <td>-0.737125</td>\n",
       "      <td>-1.164100</td>\n",
       "      <td>1.173042</td>\n",
       "      <td>0.562647</td>\n",
       "      <td>0.890118</td>\n",
       "      <td>1.366062</td>\n",
       "      <td>-1.148116</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.808129</td>\n",
       "      <td>TCGA-O1-A52J</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406 rows Ã— 17772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  ?|100133144  ?|100134869   ?|10357   ?|10431  ?|155060   ?|26823   \n",
       "0        0     0.115255     0.097686 -1.940808 -0.033268  1.057022  1.176377  \\\n",
       "1        1    -0.233267     0.219007 -0.289184  0.202607 -0.069052  1.877450   \n",
       "2        0     0.248854    -0.384813 -0.533564 -0.173685  0.583903  0.236868   \n",
       "3        0    -1.015130    -1.252003 -0.898805 -1.181021  0.757503  0.484314   \n",
       "4        1    -0.816478     0.346711 -1.143054  1.242887 -1.570895 -0.056828   \n",
       "..     ...          ...          ...       ...       ...       ...       ...   \n",
       "401      0     0.593944     0.996343 -0.009038  0.047639  0.668383  1.340455   \n",
       "402      0    -0.069018    -0.011506 -0.817153 -0.316691  1.148248  0.675043   \n",
       "403      0     1.749735     2.648401 -0.450322 -0.660086  1.016852 -0.892399   \n",
       "404      1     0.486836     1.062102 -1.368185  0.780825  0.141787  3.015645   \n",
       "405      0     0.906803    -0.184996 -0.737125 -1.164100  1.173042  0.562647   \n",
       "\n",
       "     ?|340602  ?|388795  ?|390284  ...  ZZZ3|26009    patient_id   \n",
       "0   -0.577514  1.530721  0.136966  ...   -0.447237  TCGA-05-4244  \\\n",
       "1   -0.577514  0.029955  0.027188  ...    0.096801  TCGA-05-4249   \n",
       "2    1.884460  0.123771 -0.210492  ...   -0.019820  TCGA-05-4382   \n",
       "3   -0.577514 -0.013923  0.260217  ...    0.236221  TCGA-05-4384   \n",
       "4   -0.577514 -0.166251 -0.193914  ...    0.356558  TCGA-05-4389   \n",
       "..        ...       ...       ...  ...         ...           ...   \n",
       "401 -0.577514 -1.208640 -0.104800  ...   -0.396243  TCGA-NJ-A55A   \n",
       "402  0.645656  2.908490 -1.628148  ...   -0.263652  TCGA-NJ-A55O   \n",
       "403 -0.577514  0.941106 -1.506687  ...   -1.338024  TCGA-NJ-A55R   \n",
       "404  1.099217  0.123525 -0.071799  ...   -1.000029  TCGA-NJ-A7XG   \n",
       "405  0.890118  1.366062 -1.148116  ...   -0.808129  TCGA-O1-A52J   \n",
       "\n",
       "     age_at_initial_pathologic_diagnosis_x  gender_x  tumor_stage_x   \n",
       "0                                     70.0       0.0            1.0  \\\n",
       "1                                     67.0       0.0            0.0   \n",
       "2                                      NaN       NaN            NaN   \n",
       "3                                     66.0       0.0            1.0   \n",
       "4                                     70.0       0.0            0.0   \n",
       "..                                     ...       ...            ...   \n",
       "401                                   76.0       1.0            0.0   \n",
       "402                                   56.0       1.0            0.0   \n",
       "403                                   67.0       0.0            0.0   \n",
       "404                                   49.0       0.0            1.0   \n",
       "405                                   74.0       1.0            0.0   \n",
       "\n",
       "     is_smoker_x  age_at_initial_pathologic_diagnosis_y  gender_y   \n",
       "0            1.0                                   70.0       0.0  \\\n",
       "1            1.0                                   67.0       0.0   \n",
       "2            NaN                                    NaN       NaN   \n",
       "3            1.0                                   66.0       0.0   \n",
       "4            1.0                                   70.0       0.0   \n",
       "..           ...                                    ...       ...   \n",
       "401          1.0                                   76.0       1.0   \n",
       "402          1.0                                   56.0       1.0   \n",
       "403          0.0                                   67.0       0.0   \n",
       "404          0.0                                   49.0       0.0   \n",
       "405          1.0                                   74.0       1.0   \n",
       "\n",
       "     tumor_stage_y  is_smoker_y  \n",
       "0              1.0          1.0  \n",
       "1              0.0          1.0  \n",
       "2              NaN          NaN  \n",
       "3              1.0          1.0  \n",
       "4              0.0          1.0  \n",
       "..             ...          ...  \n",
       "401            0.0          1.0  \n",
       "402            0.0          1.0  \n",
       "403            0.0          0.0  \n",
       "404            1.0          0.0  \n",
       "405            0.0          1.0  \n",
       "\n",
       "[406 rows x 17772 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ec27567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  1\n",
      "Best Score: 0.7001692601692602\n",
      "Test accuracy: 0.6341463414634146\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  2\n",
      "Best Score: 0.6855774237217537\n",
      "Test accuracy: 0.5609756097560976\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  3\n",
      "Best Score: 0.7001396102661926\n",
      "Test accuracy: 0.6341463414634146\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  4\n",
      "Best Score: 0.6983674583674583\n",
      "Test accuracy: 0.6219512195121951\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  5\n",
      "Best Score: 0.6965409743491936\n",
      "Test accuracy: 0.6219512195121951\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  6\n",
      "Best Score: 0.6855774237217537\n",
      "Test accuracy: 0.5609756097560976\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  7\n",
      "Best Score: 0.6855774237217537\n",
      "Test accuracy: 0.5609756097560976\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  8\n",
      "Best Score: 0.6855774237217537\n",
      "Test accuracy: 0.5609756097560976\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  9\n",
      "Best Score: 0.6970490209974253\n",
      "Test accuracy: 0.6341463414634146\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  10\n",
      "Best Score: 0.6965409743491936\n",
      "Test accuracy: 0.6219512195121951\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  11\n",
      "Best Score: 0.6985383584361299\n",
      "Test accuracy: 0.6219512195121951\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  12\n",
      "Best Score: 0.6855774237217537\n",
      "Test accuracy: 0.5609756097560976\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  13\n",
      "Best Score: 0.6855774237217537\n",
      "Test accuracy: 0.5609756097560976\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  14\n",
      "Best Score: 0.6855774237217537\n",
      "Test accuracy: 0.5609756097560976\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  15\n",
      "Best Score: 0.6968099633744014\n",
      "Test accuracy: 0.6219512195121951\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  16\n",
      "Best Score: 0.6855774237217537\n",
      "Test accuracy: 0.5609756097560976\n",
      "------------------------------------------\n",
      "Best Parameters: {'C': 0.5, 'kernel': 'rbf'}\n",
      "Best Score: 0.7001692601692602\n",
      "------------------------------------------\n",
      "RESULTS:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5833    0.5833    0.5833        36\n",
      "           1     0.6739    0.6739    0.6739        46\n",
      "\n",
      "    accuracy                         0.6341        82\n",
      "   macro avg     0.6286    0.6286    0.6286        82\n",
      "weighted avg     0.6341    0.6341    0.6341        82\n",
      "\n",
      "Best metadata features\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "metadata_features = meta_file.iloc[:,-4:]\n",
    "metadata_features = metadata_features.fillna(0)\n",
    "expression_features = meta_file[genes.iloc[:,0]]\n",
    "\n",
    "# Define the number of metadata columns\n",
    "num_metadata_cols = metadata_features.shape[1]\n",
    "\n",
    "# Generate permutations of metadata column indices\n",
    "metadata_permutations = []\n",
    "for r in range(0, num_metadata_cols + 1):\n",
    "    metadata_permutations.extend(combinations(range(num_metadata_cols), r))\n",
    "\n",
    "# SVM Classifier\n",
    "model = svm.SVC()\n",
    "param_grid = {'C': [0.1,0.5,1,2,5,10],\n",
    "            'kernel': ['linear','rbf',]}\n",
    "\n",
    "# List to store grid search results\n",
    "grid_search_results = []\n",
    "test_acc = []\n",
    "ind = 1\n",
    "# Iterate through the permutations\n",
    "for perm in metadata_permutations:\n",
    "    # Select the metadata columns based on the current permutation\n",
    "    selected_metadata = metadata_features.iloc[:, list(perm)]\n",
    "\n",
    "    # Concatenate the selected metadata columns with the top_100_features\n",
    "    combined_features = np.concatenate((expression_features, selected_metadata), axis=1)\n",
    "\n",
    "    # Perform train-test-split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(combined_features, meta_file.iloc[:,0], test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fit the SVM classifier on the combined features and perform classification\n",
    "    # Perform grid search cross-validation\n",
    "    print(\"------------------------------------------\")\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1', verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Save the grid search object\n",
    "    grid_search_results.append(grid_search)\n",
    "\n",
    "    print(\"Iteration \", ind)\n",
    "    best_score = grid_search.best_score_\n",
    "    print(\"Best Score:\", best_score)\n",
    "\n",
    "    # Perform prediction using the best parameters\n",
    "    y_pred = grid_search.predict(X_test) \n",
    "    # Calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('Test accuracy:', accuracy)\n",
    "    test_acc.append(accuracy)\n",
    "\n",
    "    ind += 1\n",
    "\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Find the best parameters\n",
    "max_ind = np.argmax(test_acc)\n",
    "best_result = grid_search_results[max_ind]\n",
    "best_params = grid_search_results[max_ind].best_params_\n",
    "best_score = grid_search_results[max_ind].best_score_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "print(\"------------------------------------------\")\n",
    "print('RESULTS:')\n",
    "# Perform prediction using the best parameters\n",
    "best_model = best_result.best_estimator_\n",
    "\n",
    "# Select the metadata columns based on the current permutation\n",
    "selected_metadata = metadata_features.iloc[:, list(metadata_permutations[max_ind])]\n",
    "# Concatenate the selected metadata columns with the top_100_features\n",
    "combined_features = np.concatenate((expression_features, selected_metadata), axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, meta_file.iloc[:,0], test_size=0.2, random_state=42)\n",
    "y_pred = best_model.predict(X_test) \n",
    "# print classification report\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# Added metadata features\n",
    "print('Best metadata features')\n",
    "print(metadata_features.columns[list(metadata_permutations[max_ind])])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bb61875",
   "metadata": {},
   "source": [
    "### Use XGBoost for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9b15a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02714337 0.04014812 0.04884477 0.02787161 0.02280556 0.01647362\n",
      " 0.02838358 0.03018021 0.0319785  0.02207574 0.02168249 0.03259696\n",
      " 0.06153047 0.01717239 0.03980868 0.02393797 0.0253426  0.03641458\n",
      " 0.03962428 0.05320012 0.01783607 0.0666093  0.01553164 0.02105021\n",
      " 0.01799656 0.02550105 0.04547681 0.03676377 0.02492175 0.02926498\n",
      " 0.02399425 0.02043392 0.00393278 0.00347131]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGdCAYAAAAFcOm4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmZUlEQVR4nO3df1DU953H8Reg7EYTMJHKikHRhIhGhBGFrpeL7bnjkuEuktwRtDeRcI6Z5EJruz0u4hjInXeDSUcPezBlvNY2vanR4y6hbfRo6TZ4Tdno8MOxXBMvyWix0QVJJ5BghQx874+Ma7euhkVw/bDPx8x3Kt99f7+8vx8/U1/5fL+7G2NZliUAAACDxUa6AQAAgBtFoAEAAMYj0AAAAOMRaAAAgPEINAAAwHgEGgAAYDwCDQAAMB6BBgAAGG9apBuYCKOjozp37pzuuOMOxcTERLodAAAwBpZl6aOPPlJKSopiY29sjWVKBJpz584pNTU10m0AAIBxOHv2rO6+++4bOseUCDR33HGHpE8HJCEhIcLdAACAsRgYGFBqamrg3/EbMSUCzeXbTAkJCQQaAAAMMxGPi/BQMAAAMB6BBgAAGI9AAwAAjEegAQAAxiPQAAAA4xFoAACA8Qg0AADAeAQaAABgPAINAAAwHoEGAAAYj0ADAACMR6ABAADGI9AAAADjEWgAAIDxpkW6AQCIZmnbDo+59syugknsBDAbKzQAAMB4BBoAAGA8Ag0AADAegQYAABiPQAMAAIxHoAEAAMYj0AAAAOMRaAAAgPEINAAAwHgEGgAAYDwCDQAAMB6BBgAAGI9AAwAAjEegAQAAxiPQAAAA4xFoAACA8Qg0AADAeAQaAABgPAINAAAwHoEGAAAYj0ADAACMR6ABAADGI9AAAADjEWgAAIDxCDQAAMB4BBoAAGC8aZFuAMD1pW07PObaM7sKJrETALh1sUIDAACMR6ABAADGI9AAAADjjSvQ1NXVKS0tTXa7XXl5eTp+/Ph16xsaGpSRkSG73a7MzEwdOXLkqpq33npLDz/8sBITEzVz5kytWrVK3d3d42kPAABEmbADzaFDh+TxeFRVVaWOjg5lZWXJ7Xart7c3ZH1ra6s2btyozZs3q7OzU4WFhSosLFRXV1eg5r333tMDDzygjIwMtbS06OTJk3ruuedkt9vHf2UAACBqxFiWZYVzQF5enlatWqXa2lpJ0ujoqFJTU/XlL39Z27Ztu6q+uLhYg4ODeu211wL7Pv/5zys7O1v19fWSpA0bNmj69On693//93FdxMDAgBITE9Xf36+EhIRxnQO4VfEup6mNv19Es4n89zusFZrh4WG1t7fL5XJdOUFsrFwul3w+X8hjfD5fUL0kud3uQP3o6KgOHz6s++67T263W3PmzFFeXp4aGxuv2cfQ0JAGBgaCNgAAEL3CCjR9fX0aGRlRcnJy0P7k5GT5/f6Qx/j9/uvW9/b26uOPP9auXbuUn5+vn/70p3rkkUf06KOP6ujRoyHPWV1drcTExMCWmpoazmUAAIApJuLvchodHZUkrV+/Xl/72teUnZ2tbdu26c///M8Dt6T+WEVFhfr7+wPb2bNnb2bLAADgFhPWJwUnJSUpLi5OPT09Qft7enrkcDhCHuNwOK5bn5SUpGnTpmnp0qVBNUuWLNEbb7wR8pw2m002my2c1gEAwBQW1gpNfHy8cnJy5PV6A/tGR0fl9XrldDpDHuN0OoPqJam5uTlQHx8fr1WrVunUqVNBNf/3f/+nBQsWhNMeAACIUmF/l5PH41FJSYlWrlyp3Nxc1dTUaHBwUKWlpZKkTZs2ad68eaqurpYkbd26VWvWrNHu3btVUFCggwcPqq2tTfv27Qucs7y8XMXFxXrwwQf1xS9+UU1NTfrxj3+slpaWiblKAAAwpYUdaIqLi3XhwgVVVlbK7/crOztbTU1NgQd/u7u7FRt7ZeFn9erVOnDggHbs2KHt27crPT1djY2NWrZsWaDmkUceUX19vaqrq/WVr3xFixcv1n/913/pgQcemIBLBAAAU13Yn0NzK+JzaDCV8TklUxt/v4hmEfscGgAAgFsRgQYAABiPQAMAAIxHoAEAAMYj0AAAAOMRaAAAgPEINAAAwHgEGgAAYDwCDQAAMB6BBgAAGI9AAwAAjEegAQAAxiPQAAAA4xFoAACA8Qg0AADAeAQaAABgPAINAAAwHoEGAAAYj0ADAACMR6ABAADGI9AAAADjEWgAAIDxCDQAAMB4BBoAAGA8Ag0AADAegQYAABiPQAMAAIxHoAEAAMYj0AAAAONNi3QDAHCrSdt2eMy1Z3YVTGInAMaKFRoAAGA8Ag0AADAegQYAABiPQAMAAIxHoAEAAMYj0AAAAOMRaAAAgPEINAAAwHgEGgAAYDwCDQAAMB6BBgAAGI9AAwAAjDeuQFNXV6e0tDTZ7Xbl5eXp+PHj161vaGhQRkaG7Ha7MjMzdeTIkaDXn3jiCcXExARt+fn542kNAABEobADzaFDh+TxeFRVVaWOjg5lZWXJ7Xart7c3ZH1ra6s2btyozZs3q7OzU4WFhSosLFRXV1dQXX5+vs6fPx/YXn755fFdEQAAiDphB5o9e/Zoy5YtKi0t1dKlS1VfX68ZM2Zo//79Iev37t2r/Px8lZeXa8mSJdq5c6dWrFih2traoDqbzSaHwxHY7rzzzvFdEQAAiDphBZrh4WG1t7fL5XJdOUFsrFwul3w+X8hjfD5fUL0kud3uq+pbWlo0Z84cLV68WE8//bQ++OCDa/YxNDSkgYGBoA0AAESvsAJNX1+fRkZGlJycHLQ/OTlZfr8/5DF+v/8z6/Pz8/X9739fXq9XL7zwgo4ePaqHHnpIIyMjIc9ZXV2txMTEwJaamhrOZQAAgClmWqQbkKQNGzYE/pyZmanly5frnnvuUUtLi9auXXtVfUVFhTweT+DngYEBQg0AAFEsrBWapKQkxcXFqaenJ2h/T0+PHA5HyGMcDkdY9ZK0aNEiJSUl6d133w35us1mU0JCQtAGAACiV1iBJj4+Xjk5OfJ6vYF9o6Oj8nq9cjqdIY9xOp1B9ZLU3Nx8zXpJ+u1vf6sPPvhAc+fODac9AAAQpcJ+l5PH49G//du/6aWXXtJbb72lp59+WoODgyotLZUkbdq0SRUVFYH6rVu3qqmpSbt379bbb7+t559/Xm1tbSorK5MkffzxxyovL9ebb76pM2fOyOv1av369br33nvldrsn6DIBAMBUFvYzNMXFxbpw4YIqKyvl9/uVnZ2tpqamwIO/3d3dio29kpNWr16tAwcOaMeOHdq+fbvS09PV2NioZcuWSZLi4uJ08uRJvfTSS/rwww+VkpKidevWaefOnbLZbBN0mQAAYCob10PBZWVlgRWWP9bS0nLVvqKiIhUVFYWsv+222/STn/xkPG1MSWnbDo+p7syugknuBAAAc/BdTgAAwHgEGgAAYDwCDQAAMB6BBgAAGI9AAwAAjEegAQAAxiPQAAAA4xFoAACA8Qg0AADAeAQaAABgPAINAAAwHoEGAAAYj0ADAACMR6ABAADGI9AAAADjEWgAAIDxCDQAAMB40yLdAAAAkpS27fCYa8/sKpjETmAiVmgAAIDxCDQAAMB4BBoAAGA8Ag0AADAegQYAABiPQAMAAIxHoAEAAMYj0AAAAOMRaAAAgPEINAAAwHgEGgAAYDwCDQAAMB6BBgAAGI9AAwAAjEegAQAAxiPQAAAA4xFoAACA8Qg0AADAeAQaAABgPAINAAAwHoEGAAAYj0ADAACMR6ABAADGI9AAAADjjSvQ1NXVKS0tTXa7XXl5eTp+/Ph16xsaGpSRkSG73a7MzEwdOXLkmrVPPfWUYmJiVFNTM57WAABAFAo70Bw6dEgej0dVVVXq6OhQVlaW3G63ent7Q9a3trZq48aN2rx5szo7O1VYWKjCwkJ1dXVdVfvqq6/qzTffVEpKSvhXAgAAolbYgWbPnj3asmWLSktLtXTpUtXX12vGjBnav39/yPq9e/cqPz9f5eXlWrJkiXbu3KkVK1aotrY2qO7999/Xl7/8Zf3gBz/Q9OnTx3c1AAAgKk0Lp3h4eFjt7e2qqKgI7IuNjZXL5ZLP5wt5jM/nk8fjCdrndrvV2NgY+Hl0dFSPP/64ysvLdf/9939mH0NDQxoaGgr8PDAwEM5l3BRp2w6PufbMroJJ7AQAgKkvrBWavr4+jYyMKDk5OWh/cnKy/H5/yGP8fv9n1r/wwguaNm2avvKVr4ypj+rqaiUmJga21NTUcC4DAABMMWGt0EyG9vZ27d27Vx0dHYqJiRnTMRUVFUGrPgMDA4QaYAKMdWWRVUUAt5qwAk1SUpLi4uLU09MTtL+np0cOhyPkMQ6H47r1v/jFL9Tb26v58+cHXh8ZGdHXv/511dTU6MyZM1ed02azyWazhdM6gCjF7V8gOoR1yyk+Pl45OTnyer2BfaOjo/J6vXI6nSGPcTqdQfWS1NzcHKh//PHHdfLkSZ04cSKwpaSkqLy8XD/5yU/CvR4AABCFwr7l5PF4VFJSopUrVyo3N1c1NTUaHBxUaWmpJGnTpk2aN2+eqqurJUlbt27VmjVrtHv3bhUUFOjgwYNqa2vTvn37JEmzZ8/W7Nmzg37H9OnT5XA4tHjx4hu9PgAAEAXCDjTFxcW6cOGCKisr5ff7lZ2draampsCDv93d3YqNvbLws3r1ah04cEA7duzQ9u3blZ6ersbGRi1btmzirgIAAES1cT0UXFZWprKyspCvtbS0XLWvqKhIRUVFYz5/qOdmAAAAroXvcgIAAMYj0AAAAOMRaAAAgPEINAAAwHgEGgAAYDwCDQAAMB6BBgAAGI9AAwAAjEegAQAAxiPQAAAA443rqw8AALgVpG07PObaM7sKJrETRBorNAAAwHis0AAwxlj/a5z/EgeiDys0AADAeAQaAABgPAINAAAwHoEGAAAYj0ADAACMR6ABAADGI9AAAADjEWgAAIDxCDQAAMB4BBoAAGA8Ag0AADAegQYAABiPQAMAAIxHoAEAAMYj0AAAAOMRaAAAgPEINAAAwHgEGgAAYDwCDQAAMN60SDcARJO0bYfHVHdmV8EkdwIAUwsrNAAAwHgEGgAAYDxuOWFK4ZYOAEQnVmgAAIDxCDQAAMB4BBoAAGA8Ag0AADAegQYAABiPQAMAAIw3rkBTV1entLQ02e125eXl6fjx49etb2hoUEZGhux2uzIzM3XkyJGg159//nllZGRo5syZuvPOO+VyuXTs2LHxtAYAAKJQ2IHm0KFD8ng8qqqqUkdHh7KysuR2u9Xb2xuyvrW1VRs3btTmzZvV2dmpwsJCFRYWqqurK1Bz3333qba2Vr/61a/0xhtvKC0tTevWrdOFCxfGf2UAACBqhB1o9uzZoy1btqi0tFRLly5VfX29ZsyYof3794es37t3r/Lz81VeXq4lS5Zo586dWrFihWprawM1X/rSl+RyubRo0SLdf//92rNnjwYGBnTy5MnxXxkAAIgaYX1S8PDwsNrb21VRURHYFxsbK5fLJZ/PF/IYn88nj8cTtM/tdquxsfGav2Pfvn1KTExUVlZWyJqhoSENDQ0Ffh4YGAjnMmCAsX7ir8Sn/gIAwlyh6evr08jIiJKTk4P2Jycny+/3hzzG7/ePqf61117T7bffLrvdrn/5l39Rc3OzkpKSQp6zurpaiYmJgS01NTWcywAAAFPMLfMupy9+8Ys6ceKEWltblZ+fr8cee+yaz+VUVFSov78/sJ09e/YmdwsAAG4lYQWapKQkxcXFqaenJ2h/T0+PHA5HyGMcDseY6mfOnKl7771Xn//85/Wd73xH06ZN03e+852Q57TZbEpISAjaAABA9Aor0MTHxysnJ0derzewb3R0VF6vV06nM+QxTqczqF6Smpubr1n/h+f9w+dkAAAAriWsh4IlyePxqKSkRCtXrlRubq5qamo0ODio0tJSSdKmTZs0b948VVdXS5K2bt2qNWvWaPfu3SooKNDBgwfV1tamffv2SZIGBwf1z//8z3r44Yc1d+5c9fX1qa6uTu+//76Kioom8FIBABg/3qxwaws70BQXF+vChQuqrKyU3+9Xdna2mpqaAg/+dnd3Kzb2ysLP6tWrdeDAAe3YsUPbt29Xenq6GhsbtWzZMklSXFyc3n77bb300kvq6+vT7NmztWrVKv3iF7/Q/fffP0GXCQAAprKwA40klZWVqaysLORrLS0tV+0rKiq65mqL3W7XK6+8Mp42AAAAJN1C73ICAAAYr3Gt0ADh4L4zAGCysUIDAACMR6ABAADG45bTFMAtHQBAtGOFBgAAGI9AAwAAjEegAQAAxuMZmjHgGRUAAG5trNAAAADjEWgAAIDxCDQAAMB4BBoAAGA8Ag0AADAegQYAABiPQAMAAIxHoAEAAMbjg/UA3HR8WOXUN9a/Y/5+MVFYoQEAAMYj0AAAAONxywkAEHW4JTb1sEIDAACMR6ABAADGI9AAAADj8QwNAACThI8ouHkINABuCP+HDeBWwC0nAABgPAINAAAwHoEGAAAYj0ADAACMR6ABAADG411OUYp3pgAAphJWaAAAgPEINAAAwHgEGgAAYDyeoUHU43kiADAfKzQAAMB4rNAA48CqDgDcWlihAQAAxiPQAAAA43HLCQCiBLdKMZWNa4Wmrq5OaWlpstvtysvL0/Hjx69b39DQoIyMDNntdmVmZurIkSOB1z755BM9++yzyszM1MyZM5WSkqJNmzbp3Llz42kNAABEobADzaFDh+TxeFRVVaWOjg5lZWXJ7Xart7c3ZH1ra6s2btyozZs3q7OzU4WFhSosLFRXV5ck6eLFi+ro6NBzzz2njo4OvfLKKzp16pQefvjhG7syAAAQNcK+5bRnzx5t2bJFpaWlkqT6+nodPnxY+/fv17Zt266q37t3r/Lz81VeXi5J2rlzp5qbm1VbW6v6+nolJiaqubk56Jja2lrl5uaqu7tb8+fPH891AQBgrLHeHuTW4BVhrdAMDw+rvb1dLpfrygliY+VyueTz+UIe4/P5guolye12X7Nekvr7+xUTE6NZs2aF0x4AAIhSYa3Q9PX1aWRkRMnJyUH7k5OT9fbbb4c8xu/3h6z3+/0h6y9duqRnn31WGzduVEJCQsiaoaEhDQ0NBX4eGBgI5zIAAMAUc0u9bfuTTz7RY489Jsuy9K1vfeuaddXV1UpMTAxsqampN7FLAABwqwkr0CQlJSkuLk49PT1B+3t6euRwOEIe43A4xlR/Ocz85je/UXNz8zVXZySpoqJC/f39ge3s2bPhXAYAAJhiwgo08fHxysnJkdfrDewbHR2V1+uV0+kMeYzT6Qyql6Tm5uag+sth5p133tHPfvYzzZ49+7p92Gw2JSQkBG0AACB6hf0uJ4/Ho5KSEq1cuVK5ubmqqanR4OBg4F1PmzZt0rx581RdXS1J2rp1q9asWaPdu3eroKBABw8eVFtbm/bt2yfp0zDzV3/1V+ro6NBrr72mkZGRwPM1d911l+Lj4yfqWgEAwBQVdqApLi7WhQsXVFlZKb/fr+zsbDU1NQUe/O3u7lZs7JWFn9WrV+vAgQPasWOHtm/frvT0dDU2NmrZsmWSpPfff18/+tGPJEnZ2dlBv+v111/XF77whXFeGgAAiBbj+uqDsrIylZWVhXytpaXlqn1FRUUqKioKWZ+WlibLssbTBgAAgKRb7F1OAAAA40GgAQAAxiPQAAAA4xFoAACA8cb1UDAAIDqM9UsSJb4oEZFFoAGACcI//kDkcMsJAAAYj0ADAACMR6ABAADG4xkaYAriWQ4A0YYVGgAAYDwCDQAAMB63nBCWsd7K4DYGAOBmYoUGAAAYj0ADAACMR6ABAADGI9AAAADj8VAwABiIB/SBYKzQAAAA4xFoAACA8Qg0AADAeAQaAABgPAINAAAwHoEGAAAYj0ADAACMR6ABAADGI9AAAADjEWgAAIDxCDQAAMB4BBoAAGA8Ag0AADAegQYAABiPQAMAAIxHoAEAAMYj0AAAAOMRaAAAgPEINAAAwHgEGgAAYDwCDQAAMB6BBgAAGI9AAwAAjEegAQAAxhtXoKmrq1NaWprsdrvy8vJ0/Pjx69Y3NDQoIyNDdrtdmZmZOnLkSNDrr7zyitatW6fZs2crJiZGJ06cGE9bAAAgSoUdaA4dOiSPx6Oqqip1dHQoKytLbrdbvb29IetbW1u1ceNGbd68WZ2dnSosLFRhYaG6uroCNYODg3rggQf0wgsvjP9KAABA1Ao70OzZs0dbtmxRaWmpli5dqvr6es2YMUP79+8PWb93717l5+ervLxcS5Ys0c6dO7VixQrV1tYGah5//HFVVlbK5XKN/0oAAEDUCivQDA8Pq729PSh4xMbGyuVyyefzhTzG5/NdFVTcbvc168diaGhIAwMDQRsAAIheYQWavr4+jYyMKDk5OWh/cnKy/H5/yGP8fn9Y9WNRXV2txMTEwJaamjrucwEAAPMZ+S6niooK9ff3B7azZ89GuiUAABBB08IpTkpKUlxcnHp6eoL29/T0yOFwhDzG4XCEVT8WNptNNptt3McDAICpJawVmvj4eOXk5Mjr9Qb2jY6Oyuv1yul0hjzG6XQG1UtSc3PzNesBAADCFdYKjSR5PB6VlJRo5cqVys3NVU1NjQYHB1VaWipJ2rRpk+bNm6fq6mpJ0tatW7VmzRrt3r1bBQUFOnjwoNra2rRv377AOX/3u9+pu7tb586dkySdOnVK0qerOzeykgMAAKJD2IGmuLhYFy5cUGVlpfx+v7Kzs9XU1BR48Le7u1uxsVcWflavXq0DBw5ox44d2r59u9LT09XY2Khly5YFan70ox8FApEkbdiwQZJUVVWl559/frzXBgAAokTYgUaSysrKVFZWFvK1lpaWq/YVFRWpqKjomud74okn9MQTT4ynFQAAADPf5QQAAPCHCDQAAMB4BBoAAGA8Ag0AADAegQYAABiPQAMAAIxHoAEAAMYj0AAAAOMRaAAAgPEINAAAwHgEGgAAYDwCDQAAMB6BBgAAGI9AAwAAjEegAQAAxiPQAAAA4xFoAACA8Qg0AADAeAQaAABgPAINAAAwHoEGAAAYj0ADAACMR6ABAADGI9AAAADjEWgAAIDxpkW6AQAAcOPSth0ec+2ZXQWT2ElksEIDAACMR6ABAADG45YTAABRairdpmKFBgAAGI9AAwAAjEegAQAAxiPQAAAA4xFoAACA8Qg0AADAeAQaAABgPAINAAAwHoEGAAAYj0ADAACMR6ABAADGI9AAAADjEWgAAIDxxhVo6urqlJaWJrvdrry8PB0/fvy69Q0NDcrIyJDdbldmZqaOHDkS9LplWaqsrNTcuXN12223yeVy6Z133hlPawAAIAqFHWgOHTokj8ejqqoqdXR0KCsrS263W729vSHrW1tbtXHjRm3evFmdnZ0qLCxUYWGhurq6AjUvvviivvnNb6q+vl7Hjh3TzJkz5Xa7denSpfFfGQAAiBphB5o9e/Zoy5YtKi0t1dKlS1VfX68ZM2Zo//79Iev37t2r/Px8lZeXa8mSJdq5c6dWrFih2tpaSZ+uztTU1GjHjh1av369li9fru9///s6d+6cGhsbb+jiAABAdJgWTvHw8LDa29tVUVER2BcbGyuXyyWfzxfyGJ/PJ4/HE7TP7XYHwsrp06fl9/vlcrkCrycmJiovL08+n08bNmy46pxDQ0MaGhoK/Nzf3y9JGhgYCOdyxmx06OKYay/3MJ5jwjluPMf84XH0R3838rvoz5zfRX839rvoL/TvmiiXz2lZ1o2fzArD+++/b0myWltbg/aXl5dbubm5IY+ZPn26deDAgaB9dXV11pw5cyzLsqxf/vKXliTr3LlzQTVFRUXWY489FvKcVVVVliQ2NjY2Nja2KbCdPXs2nDgSUlgrNLeKioqKoFWf0dFR/e53v9Ps2bMVExMz6b9/YGBAqampOnv2rBISEib9993KGIsrGItPMQ5XMBZXMBZXMBafujwOv/71r5WSknLD5wsr0CQlJSkuLk49PT1B+3t6euRwOEIe43A4rlt/+X97eno0d+7coJrs7OyQ57TZbLLZbEH7Zs2aFc6lTIiEhISonox/iLG4grH4FONwBWNxBWNxBWPxqXnz5ik29sY/RSasM8THxysnJ0derzewb3R0VF6vV06nM+QxTqczqF6SmpubA/ULFy6Uw+EIqhkYGNCxY8eueU4AAIA/FPYtJ4/Ho5KSEq1cuVK5ubmqqanR4OCgSktLJUmbNm3SvHnzVF1dLUnaunWr1qxZo927d6ugoEAHDx5UW1ub9u3bJ0mKiYnRV7/6Vf3TP/2T0tPTtXDhQj333HNKSUlRYWHhxF0pAACYssIONMXFxbpw4YIqKyvl9/uVnZ2tpqYmJScnS5K6u7uDlo5Wr16tAwcOaMeOHdq+fbvS09PV2NioZcuWBWr+/u//XoODg3ryySf14Ycf6oEHHlBTU5PsdvsEXOLEs9lsqqqquuq2VzRiLK5gLD7FOFzBWFzBWFzBWHxqoschxrIm4r1SAAAAkcN3OQEAAOMRaAAAgPEINAAAwHgEGgAAYDwCzTjU1dUpLS1NdrtdeXl5On78eKRbuumef/55xcTEBG0ZGRmRbuum+J//+R/9xV/8hVJSUhQTE3PVl6halqXKykrNnTtXt912m1wul955553INDuJPmscnnjiiavmSH5+fmSanUTV1dVatWqV7rjjDs2ZM0eFhYU6depUUM2lS5f0zDPPaPbs2br99tv1l3/5l1d94OhUMJax+MIXvnDVvHjqqaci1PHk+da3vqXly5cHPjzP6XTqv//7vwOvR8uckD57LCZqThBownTo0CF5PB5VVVWpo6NDWVlZcrvd6u3tjXRrN93999+v8+fPB7Y33ngj0i3dFIODg8rKylJdXV3I11988UV985vfVH19vY4dO6aZM2fK7Xbr0qVLN7nTyfVZ4yBJ+fn5QXPk5Zdfvokd3hxHjx7VM888ozfffFPNzc365JNPtG7dOg0ODgZqvva1r+nHP/6xGhoadPToUZ07d06PPvpoBLueHGMZC0nasmVL0Lx48cUXI9Tx5Ln77ru1a9cutbe3q62tTX/2Z3+m9evX63//938lRc+ckD57LKQJmhM3/G1QUSY3N9d65plnAj+PjIxYKSkpVnV1dQS7uvmqqqqsrKysSLcRcZKsV199NfDz6Oio5XA4rG984xuBfR9++KFls9msl19+OQId3hx/PA6WZVklJSXW+vXrI9JPJPX29lqSrKNHj1qW9enf//Tp062GhoZAzVtvvWVJsnw+X6TavCn+eCwsy7LWrFljbd26NXJNRdCdd95pffvb347qOXHZ5bGwrImbE6zQhGF4eFjt7e1yuVyBfbGxsXK5XPL5fBHsLDLeeecdpaSkaNGiRfrrv/5rdXd3R7qliDt9+rT8fn/QHElMTFReXl5UzpGWlhbNmTNHixcv1tNPP60PPvgg0i1Nuv7+fknSXXfdJUlqb2/XJ598EjQnMjIyNH/+/Ck/J/54LC77wQ9+oKSkJC1btkwVFRW6ePFiJNq7aUZGRnTw4EENDg7K6XRG9Zz447G4bCLmhJHfth0pfX19GhkZCXwq8mXJycl6++23I9RVZOTl5el73/ueFi9erPPnz+sf/uEf9Kd/+qfq6urSHXfcEen2Isbv90tSyDly+bVokZ+fr0cffVQLFy7Ue++9p+3bt+uhhx6Sz+dTXFxcpNubFKOjo/rqV7+qP/mTPwl8Grrf71d8fPxVX6A71edEqLGQpC996UtasGCBUlJSdPLkST377LM6deqUXnnllQh2Ozl+9atfyel06tKlS7r99tv16quvaunSpTpx4kTUzYlrjYU0cXOCQINxeeihhwJ/Xr58ufLy8rRgwQL9x3/8hzZv3hzBznCr2LBhQ+DPmZmZWr58ue655x61tLRo7dq1Eexs8jzzzDPq6uqKmufJrudaY/Hkk08G/pyZmam5c+dq7dq1eu+993TPPffc7DYn1eLFi3XixAn19/frP//zP1VSUqKjR49Guq2IuNZYLF26dMLmBLecwpCUlKS4uLirnkTv6emRw+GIUFe3hlmzZum+++7Tu+++G+lWIuryPGCOXG3RokVKSkqasnOkrKxMr732ml5//XXdfffdgf0Oh0PDw8P68MMPg+qn8py41liEkpeXJ0lTcl7Ex8fr3nvvVU5Ojqqrq5WVlaW9e/dG5Zy41liEMt45QaAJQ3x8vHJycuT1egP7RkdH5fV6g+4FRqOPP/5Y7733nubOnRvpViJq4cKFcjgcQXNkYGBAx44di/o58tvf/lYffPDBlJsjlmWprKxMr776qn7+859r4cKFQa/n5ORo+vTpQXPi1KlT6u7unnJz4rPGIpQTJ05I0pSbF6GMjo5qaGgoqubEtVwei1DGPSdu+LHiKHPw4EHLZrNZ3/ve96xf//rX1pNPPmnNmjXL8vv9kW7tpvr6179utbS0WKdPn7Z++ctfWi6Xy0pKSrJ6e3sj3dqk++ijj6zOzk6rs7PTkmTt2bPH6uzstH7zm99YlmVZu3btsmbNmmX98Ic/tE6ePGmtX7/eWrhwofX73/8+wp1PrOuNw0cffWT93d/9neXz+azTp09bP/vZz6wVK1ZY6enp1qVLlyLd+oR6+umnrcTERKulpcU6f/58YLt48WKg5qmnnrLmz59v/fznP7fa2tosp9NpOZ3OCHY9OT5rLN59913rH//xH622tjbr9OnT1g9/+ENr0aJF1oMPPhjhzifetm3brKNHj1qnT5+2Tp48aW3bts2KiYmxfvrTn1qWFT1zwrKuPxYTOScINOPwr//6r9b8+fOt+Ph4Kzc313rzzTcj3dJNV1xcbM2dO9eKj4+35s2bZxUXF1vvvvtupNu6KV5//XVL0lVbSUmJZVmfvnX7ueees5KTky2bzWatXbvWOnXqVGSbngTXG4eLFy9a69atsz73uc9Z06dPtxYsWGBt2bJlSgb/UGMgyfrud78bqPn9739v/e3f/q115513WjNmzLAeeeQR6/z585FrepJ81lh0d3dbDz74oHXXXXdZNpvNuvfee63y8nKrv78/so1Pgr/5m7+xFixYYMXHx1uf+9znrLVr1wbCjGVFz5ywrOuPxUTOiRjLsqzw1nQAAABuLTxDAwAAjEegAQAAxiPQAAAA4xFoAACA8Qg0AADAeAQaAABgPAINAAAwHoEGAAAYj0ADAACMR6ABAADGI9AAAADjEWgAAIDx/h9pf8POejnbDQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# Define dataset as all features\n",
    "total_features = np.concatenate((expression_features, metadata_features), axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(total_features, meta_file.iloc[:,0], test_size=0.2, random_state=42)\n",
    "\n",
    "# fit model\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# feature importance\n",
    "print(model.feature_importances_)\n",
    "# plot\n",
    "pyplot.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1a10af5",
   "metadata": {},
   "source": [
    "#### Using feature importances, perform search over various thresholds with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d49783dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.000, n=34, Accuracy: 59.76%\n",
      "Thresh=0.001, n=34, Accuracy: 59.76%\n",
      "Thresh=0.001, n=34, Accuracy: 59.76%\n",
      "Thresh=0.002, n=34, Accuracy: 59.76%\n",
      "Thresh=0.002, n=34, Accuracy: 59.76%\n",
      "Thresh=0.003, n=34, Accuracy: 59.76%\n",
      "Thresh=0.003, n=34, Accuracy: 59.76%\n",
      "Thresh=0.004, n=33, Accuracy: 60.98%\n",
      "Thresh=0.004, n=32, Accuracy: 60.98%\n",
      "Thresh=0.005, n=32, Accuracy: 60.98%\n",
      "Thresh=0.005, n=32, Accuracy: 60.98%\n",
      "Thresh=0.005, n=32, Accuracy: 60.98%\n",
      "Thresh=0.006, n=32, Accuracy: 60.98%\n",
      "Thresh=0.007, n=32, Accuracy: 60.98%\n",
      "Thresh=0.007, n=32, Accuracy: 60.98%\n",
      "Thresh=0.007, n=32, Accuracy: 60.98%\n",
      "Thresh=0.008, n=32, Accuracy: 60.98%\n",
      "Thresh=0.009, n=32, Accuracy: 60.98%\n",
      "Thresh=0.009, n=32, Accuracy: 60.98%\n",
      "Thresh=0.009, n=32, Accuracy: 60.98%\n",
      "Thresh=0.010, n=32, Accuracy: 60.98%\n",
      "Thresh=0.011, n=32, Accuracy: 60.98%\n",
      "Thresh=0.011, n=32, Accuracy: 60.98%\n",
      "Thresh=0.011, n=32, Accuracy: 60.98%\n",
      "Thresh=0.012, n=32, Accuracy: 60.98%\n",
      "Thresh=0.013, n=32, Accuracy: 60.98%\n",
      "Thresh=0.013, n=32, Accuracy: 60.98%\n",
      "Thresh=0.013, n=32, Accuracy: 60.98%\n",
      "Thresh=0.014, n=32, Accuracy: 60.98%\n",
      "Thresh=0.015, n=32, Accuracy: 60.98%\n",
      "Thresh=0.015, n=32, Accuracy: 60.98%\n",
      "Thresh=0.015, n=32, Accuracy: 60.98%\n",
      "Thresh=0.016, n=31, Accuracy: 62.20%\n",
      "Thresh=0.017, n=30, Accuracy: 60.98%\n",
      "Thresh=0.017, n=30, Accuracy: 60.98%\n",
      "Thresh=0.018, n=29, Accuracy: 58.54%\n",
      "Thresh=0.018, n=27, Accuracy: 58.54%\n",
      "Thresh=0.018, n=27, Accuracy: 58.54%\n",
      "Thresh=0.019, n=27, Accuracy: 58.54%\n",
      "Thresh=0.019, n=27, Accuracy: 58.54%\n",
      "Thresh=0.020, n=27, Accuracy: 58.54%\n",
      "Thresh=0.021, n=26, Accuracy: 58.54%\n",
      "Thresh=0.021, n=26, Accuracy: 58.54%\n",
      "Thresh=0.022, n=25, Accuracy: 58.54%\n",
      "Thresh=0.022, n=24, Accuracy: 58.54%\n",
      "Thresh=0.022, n=23, Accuracy: 60.98%\n",
      "Thresh=0.023, n=22, Accuracy: 60.98%\n",
      "Thresh=0.024, n=22, Accuracy: 60.98%\n",
      "Thresh=0.024, n=20, Accuracy: 56.10%\n",
      "Thresh=0.025, n=20, Accuracy: 56.10%\n",
      "Thresh=0.025, n=19, Accuracy: 56.10%\n",
      "Thresh=0.026, n=18, Accuracy: 54.88%\n",
      "Thresh=0.026, n=17, Accuracy: 53.66%\n",
      "Thresh=0.026, n=17, Accuracy: 53.66%\n",
      "Thresh=0.027, n=17, Accuracy: 53.66%\n",
      "Thresh=0.028, n=16, Accuracy: 58.54%\n",
      "Thresh=0.028, n=15, Accuracy: 56.10%\n",
      "Thresh=0.029, n=14, Accuracy: 59.76%\n",
      "Thresh=0.029, n=14, Accuracy: 59.76%\n",
      "Thresh=0.030, n=13, Accuracy: 64.63%\n",
      "Thresh=0.030, n=13, Accuracy: 64.63%\n",
      "Thresh=0.030, n=12, Accuracy: 62.20%\n",
      "Thresh=0.031, n=12, Accuracy: 62.20%\n",
      "Thresh=0.032, n=12, Accuracy: 62.20%\n",
      "Thresh=0.032, n=11, Accuracy: 65.85%\n",
      "Thresh=0.033, n=11, Accuracy: 65.85%\n",
      "Thresh=0.033, n=10, Accuracy: 67.07%\n",
      "Thresh=0.034, n=10, Accuracy: 67.07%\n",
      "Thresh=0.034, n=10, Accuracy: 67.07%\n",
      "Thresh=0.035, n=10, Accuracy: 67.07%\n",
      "Thresh=0.035, n=10, Accuracy: 67.07%\n",
      "Thresh=0.036, n=10, Accuracy: 67.07%\n",
      "Thresh=0.036, n=10, Accuracy: 67.07%\n",
      "Thresh=0.036, n=9, Accuracy: 62.20%\n",
      "Thresh=0.037, n=8, Accuracy: 59.76%\n",
      "Thresh=0.037, n=8, Accuracy: 59.76%\n",
      "Thresh=0.038, n=8, Accuracy: 59.76%\n",
      "Thresh=0.038, n=8, Accuracy: 59.76%\n",
      "Thresh=0.039, n=8, Accuracy: 59.76%\n",
      "Thresh=0.040, n=8, Accuracy: 59.76%\n",
      "Thresh=0.040, n=6, Accuracy: 62.20%\n",
      "Thresh=0.041, n=5, Accuracy: 67.07%\n",
      "Thresh=0.041, n=5, Accuracy: 67.07%\n",
      "Thresh=0.042, n=5, Accuracy: 67.07%\n",
      "Thresh=0.042, n=5, Accuracy: 67.07%\n",
      "Thresh=0.043, n=5, Accuracy: 67.07%\n",
      "Thresh=0.043, n=5, Accuracy: 67.07%\n",
      "Thresh=0.044, n=5, Accuracy: 67.07%\n",
      "Thresh=0.044, n=5, Accuracy: 67.07%\n",
      "Thresh=0.044, n=5, Accuracy: 67.07%\n",
      "Thresh=0.045, n=5, Accuracy: 67.07%\n",
      "Thresh=0.045, n=4, Accuracy: 62.20%\n",
      "Thresh=0.046, n=4, Accuracy: 62.20%\n",
      "Thresh=0.046, n=4, Accuracy: 62.20%\n",
      "Thresh=0.047, n=4, Accuracy: 62.20%\n",
      "Thresh=0.048, n=4, Accuracy: 62.20%\n",
      "Thresh=0.048, n=4, Accuracy: 62.20%\n",
      "Thresh=0.049, n=4, Accuracy: 62.20%\n",
      "Thresh=0.049, n=3, Accuracy: 58.54%\n",
      "Thresh=0.050, n=3, Accuracy: 58.54%\n",
      "Thresh=0.050, n=3, Accuracy: 58.54%\n",
      "Thresh=0.051, n=3, Accuracy: 58.54%\n",
      "Thresh=0.051, n=3, Accuracy: 58.54%\n",
      "Thresh=0.052, n=3, Accuracy: 58.54%\n",
      "Thresh=0.052, n=3, Accuracy: 58.54%\n",
      "Thresh=0.052, n=3, Accuracy: 58.54%\n",
      "Thresh=0.053, n=3, Accuracy: 58.54%\n",
      "Thresh=0.053, n=2, Accuracy: 56.10%\n",
      "Thresh=0.054, n=2, Accuracy: 56.10%\n",
      "Thresh=0.054, n=2, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "RESULTS:\n",
      "Thresh=0.033, n=10, Accuracy: 67.07%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "        \n",
    "# Define the list of thresholds\n",
    "thresholds = np.arange(0, 0.055, 0.0005)\n",
    "n = []\n",
    "best_threshold = []\n",
    "test_acc = []\n",
    "for thresh in thresholds:\n",
    "\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Select features using the threshold\n",
    "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(X_train)\n",
    "    \n",
    "    # Train the model\n",
    "    selection_model = XGBClassifier()\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    select_X_test = selection.transform(X_test)\n",
    "    y_pred = selection_model.predict(select_X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n",
    "    best_threshold.append(thresh)\n",
    "    n.append(select_X_train.shape[1])\n",
    "    test_acc.append(accuracy)\n",
    "\n",
    "print(\"------------------------------------------\")\n",
    "print('RESULTS:')\n",
    "best_acc_ind = np.argmax(test_acc)\n",
    "best_acc = np.max(test_acc)\n",
    "best_threshold = best_threshold[best_acc_ind]\n",
    "best_n = n[best_acc_ind]\n",
    "print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (best_threshold,best_n, best_acc*100.0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8f07ec4",
   "metadata": {},
   "source": [
    "#### Do it with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "def15de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  1\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.000, n=34, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  2\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.001, n=34, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  3\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.002, n=34, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  4\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.003, n=34, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  5\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.004, n=32, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  6\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.005, n=32, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  7\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.006, n=32, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  8\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.007, n=32, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  9\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.008, n=32, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  10\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.009, n=32, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  11\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.010, n=32, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  12\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.011, n=32, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  13\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.012, n=32, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  14\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.013, n=32, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  15\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.014, n=32, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  16\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.015, n=32, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  17\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.016, n=31, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  18\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.017, n=30, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  19\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.018, n=27, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  20\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.019, n=27, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  21\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.020, n=27, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  22\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.021, n=26, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  23\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.022, n=24, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  24\n",
      "Best Score: 0.6855774237217537\n",
      "Thresh=0.023, n=22, Accuracy: 56.10%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  25\n",
      "Best Score: 0.7005121264674257\n",
      "Thresh=0.024, n=20, Accuracy: 63.41%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  26\n",
      "Best Score: 0.6952365528140175\n",
      "Thresh=0.025, n=19, Accuracy: 60.98%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  27\n",
      "Best Score: 0.6901650581267823\n",
      "Thresh=0.026, n=17, Accuracy: 60.98%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  28\n",
      "Best Score: 0.6901650581267823\n",
      "Thresh=0.027, n=17, Accuracy: 60.98%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  29\n",
      "Best Score: 0.6955915087102803\n",
      "Thresh=0.028, n=15, Accuracy: 67.07%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  30\n",
      "Best Score: 0.6916494283968321\n",
      "Thresh=0.029, n=14, Accuracy: 63.41%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  31\n",
      "Best Score: 0.6891975734978952\n",
      "Thresh=0.030, n=13, Accuracy: 65.85%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  32\n",
      "Best Score: 0.6939861975086523\n",
      "Thresh=0.031, n=12, Accuracy: 65.85%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  33\n",
      "Best Score: 0.7017299562138747\n",
      "Thresh=0.032, n=11, Accuracy: 62.20%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  34\n",
      "Best Score: 0.7261953589698427\n",
      "Thresh=0.033, n=10, Accuracy: 63.41%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  35\n",
      "Best Score: 0.7261953589698427\n",
      "Thresh=0.034, n=10, Accuracy: 63.41%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  36\n",
      "Best Score: 0.7261953589698427\n",
      "Thresh=0.035, n=10, Accuracy: 63.41%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  37\n",
      "Best Score: 0.7261953589698427\n",
      "Thresh=0.036, n=10, Accuracy: 63.41%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  38\n",
      "Best Score: 0.7160057406804394\n",
      "Thresh=0.037, n=8, Accuracy: 65.85%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  39\n",
      "Best Score: 0.7160057406804394\n",
      "Thresh=0.038, n=8, Accuracy: 65.85%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  40\n",
      "Best Score: 0.7160057406804394\n",
      "Thresh=0.039, n=8, Accuracy: 65.85%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  41\n",
      "Best Score: 0.6993545544024087\n",
      "Thresh=0.040, n=6, Accuracy: 64.63%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  42\n",
      "Best Score: 0.6962354331310688\n",
      "Thresh=0.041, n=5, Accuracy: 64.63%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  43\n",
      "Best Score: 0.6962354331310688\n",
      "Thresh=0.042, n=5, Accuracy: 64.63%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  44\n",
      "Best Score: 0.6962354331310688\n",
      "Thresh=0.043, n=5, Accuracy: 64.63%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  45\n",
      "Best Score: 0.6962354331310688\n",
      "Thresh=0.044, n=5, Accuracy: 64.63%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  46\n",
      "Best Score: 0.6962354331310688\n",
      "Thresh=0.045, n=5, Accuracy: 64.63%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  47\n",
      "Best Score: 0.6858847630044497\n",
      "Thresh=0.046, n=4, Accuracy: 71.95%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  48\n",
      "Best Score: 0.6858847630044497\n",
      "Thresh=0.047, n=4, Accuracy: 71.95%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  49\n",
      "Best Score: 0.6858847630044497\n",
      "Thresh=0.048, n=4, Accuracy: 71.95%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  50\n",
      "Best Score: 0.691755621167386\n",
      "Thresh=0.049, n=3, Accuracy: 69.51%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  51\n",
      "Best Score: 0.691755621167386\n",
      "Thresh=0.050, n=3, Accuracy: 69.51%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  52\n",
      "Best Score: 0.691755621167386\n",
      "Thresh=0.051, n=3, Accuracy: 69.51%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  53\n",
      "Best Score: 0.691755621167386\n",
      "Thresh=0.052, n=3, Accuracy: 69.51%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  54\n",
      "Best Score: 0.691755621167386\n",
      "Thresh=0.053, n=3, Accuracy: 69.51%\n",
      "------------------------------------------\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Iteration  55\n",
      "Best Score: 0.6843274853801169\n",
      "Thresh=0.054, n=2, Accuracy: 68.29%\n",
      "------------------------------------------\n",
      "RESULTS:\n",
      "Thresh=0.046, n=4, Accuracy: 71.95%\n"
     ]
    }
   ],
   "source": [
    "n = []\n",
    "best_threshold = []\n",
    "test_acc = []\n",
    "ind = 1\n",
    "thresholds = np.arange(0, 0.055, 0.001)\n",
    "\n",
    "# SVM Classifier\n",
    "model = svm.SVC()\n",
    "param_grid = {'C': [0.1,0.5,1,2,5,10],\n",
    "            'kernel': ['linear','rbf',]}\n",
    "grid_search_results = []\n",
    "            \n",
    "for thresh in thresholds:\n",
    "\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Select features using the threshold\n",
    "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(X_train)\n",
    "    \n",
    "    # Train the model\n",
    "    selection_model = XGBClassifier()\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "\n",
    "\n",
    "    # Fit the SVM classifier on the combined features and perform classification\n",
    "    # Perform grid search cross-validation\n",
    "    model = svm.SVC()\n",
    "    print(\"------------------------------------------\")\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1', verbose=1)\n",
    "    grid_search.fit(select_X_train, y_train)\n",
    "\n",
    "    # Save the grid search object\n",
    "    # grid_search_results.append(grid_search)\n",
    "\n",
    "    print(\"Iteration \", ind)\n",
    "    best_score = grid_search.best_score_\n",
    "    print(\"Best Score:\", best_score)\n",
    "    grid_search_results.append(grid_search)\n",
    "    ind += 1\n",
    "\n",
    "    # Evaluate the model\n",
    "    select_X_test = selection.transform(X_test)\n",
    "    # Perform prediction using the best parameters\n",
    "    y_pred = grid_search.predict(select_X_test) \n",
    "    # Calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n",
    "    best_threshold.append(thresh)\n",
    "    n.append(select_X_train.shape[1])\n",
    "    test_acc.append(accuracy)\n",
    "\n",
    "print(\"------------------------------------------\")\n",
    "print('RESULTS:')\n",
    "best_acc_ind = np.argmax(test_acc)\n",
    "best_acc = np.max(test_acc)\n",
    "best_threshold = best_threshold[best_acc_ind]\n",
    "best_n = n[best_acc_ind]\n",
    "print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (best_threshold,best_n, best_acc*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f41d44e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8a5a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
